{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Experiment - 3 ** \n",
    "\n",
    "Predicting the segment of audience based on \"watch patterns\"\n",
    "\n",
    "1. Load dataset\n",
    "2. Build a basic ensemble model\n",
    "   * Genres OHE with watch time\n",
    "3. Cross-validate\n",
    "4. Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "sns.set_style('dark')\n",
    "\n",
    "SEED = 2123\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%run ../src/models/cross_validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/raw/5f828822-4--4-hotstar_dataset/train_data.json', 'r') as infile:\n",
    "    train_json = json.load(infile)\n",
    "    train      = pd.DataFrame.from_dict(train_json, orient='index')\n",
    "    \n",
    "    train.reset_index(level=0, inplace=True)\n",
    "    train.rename(columns = {'index':'ID'},inplace=True)\n",
    "    \n",
    "    infile.close()\n",
    "    \n",
    "with open('../data/raw/5f828822-4--4-hotstar_dataset/test_data.json') as infile:\n",
    "    test_json = json.load(infile)\n",
    "    \n",
    "    test = pd.DataFrame.from_dict(test_json, orient='index')\n",
    "    test.reset_index(level=0, inplace=True)\n",
    "    test.rename(columns = {'index':'ID'},inplace=True)\n",
    "    \n",
    "    infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode segment variable\n",
    "lbl = LabelEncoder()\n",
    "lbl.fit(train['segment'])\n",
    "\n",
    "train['segment'] = lbl.transform(train['segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data       = pd.concat((train, test))\n",
    "train_mask = data.segment.notnull()\n",
    "\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.923725\n",
       "1.0    0.076275\n",
       "Name: segment, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[train_mask, 'segment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Huge class imbalance **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genre_dict_train = data.loc[train_mask, 'genres'].map(lambda x: x.split(','))\\\n",
    "                     .map(lambda x: dict((k.strip(), int(v.strip())) for k,v in \n",
    "                                          (item.split(':') for item in x)))\n",
    "\n",
    "genre_dict_test  = data.loc[~train_mask, 'genres'].map(lambda x: x.split(','))\\\n",
    "                     .map(lambda x: dict((k.strip(), int(v.strip())) for k,v in \n",
    "                                          (item.split(':') for item in x)))\n",
    "    \n",
    "dv    = DictVectorizer(sparse=False)\n",
    "X     = dv.fit_transform(genre_dict_train)\n",
    "Xtest = dv.transform(genre_dict_test)\n",
    "\n",
    "y     = data.loc[train_mask, 'segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert it into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "Xtest = pd.DataFrame(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'stratify': y,\n",
    "    'test_size': .3,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(X, y, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auc_scores = cross_validation(X_train, y_train, rf, 'auc', SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC score: 0.726302474069734 and std: 0.004106034401338635\n"
     ]
    }
   ],
   "source": [
    "print('Mean AUC score: {0} and std: {1}'.format(np.mean(auc_scores), np.std(auc_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rfccv(n_estimators, min_samples_split, max_depth):\n",
    "    skf = StratifiedKFold(n_splits=3, random_state=SEED)\n",
    "    val = cross_val_score(\n",
    "        RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "                               min_samples_split=int(min_samples_split),\n",
    "                               max_depth=int(max_depth),\n",
    "                               random_state=SEED\n",
    "                              ),\n",
    "        X_train, y_train, scoring='roc_auc', cv=skf\n",
    "    ).mean()\n",
    "    \n",
    "    return val\n",
    "\n",
    "def logccv(C):\n",
    "    skf = StratifiedKFold(n_splits=3, random_state=SEED)\n",
    "    \n",
    "    val = cross_val_score(\n",
    "        LogisticRegression(C=C,\n",
    "        n_jobs=2,\n",
    "        class_weight='balanced',\n",
    "        random_state=SEED\n",
    "                          ),\n",
    "        X_train, y_train, scoring='roc_auc', cv=skf\n",
    "    ).mean()\n",
    "    \n",
    "    return val\n",
    "\n",
    "def parameter_search(rf):\n",
    "    gp_params = {\n",
    "        'alpha': 1e-5\n",
    "    }\n",
    "    \n",
    "    if rf:\n",
    "        rfcBO = BayesianOptimization(\n",
    "            rfccv,\n",
    "            {\n",
    "                'n_estimators': (10, 250),\n",
    "                'min_samples_split': (2, 25),\n",
    "                'max_depth': (5, 30)\n",
    "            }\n",
    "        )\n",
    "        rfcBO.maximize(n_iter=10, **gp_params)\n",
    "        print('RFC: %f' % rfcBO.res['max']['max_val'])\n",
    "        \n",
    "    else:\n",
    "        logcBO = BayesianOptimization(\n",
    "            logccv,\n",
    "            {\n",
    "                'C': (.01, 100)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        logcBO.maximize(n_iter=10, **gp_params)\n",
    "        print('Logistic Regression: %f' % logcBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   min_samples_split |   n_estimators | \n",
      "    1 | 00m53s | \u001b[35m   0.80459\u001b[0m | \u001b[32m    11.0137\u001b[0m | \u001b[32m            19.4458\u001b[0m | \u001b[32m      219.2036\u001b[0m | \n",
      "    2 | 00m23s |    0.80423 |     11.7281 |             13.2054 |        99.5782 | \n",
      "    3 | 00m34s |    0.80259 |     21.9016 |             15.4192 |        89.8688 | \n",
      "    4 | 00m41s |    0.80390 |     18.5479 |             17.9585 |       112.5680 | \n",
      "    5 | 00m06s |    0.78984 |     27.4873 |             12.0620 |        15.9280 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   min_samples_split |   n_estimators | \n",
      "    6 | 01m56s |    0.79740 |     29.5030 |              2.7283 |       249.8664 | \n",
      "    7 | 00m30s |    0.79951 |      5.0023 |              2.0597 |       150.5581 | \n",
      "    8 | 00m48s |    0.79994 |      5.3797 |             24.9607 |       249.1496 | \n",
      "    9 | 01m17s |    0.80122 |     29.8441 |             24.9797 |       171.1445 | \n",
      "   10 | 00m56s |    0.80111 |      6.1982 |             24.1068 |       249.8762 | \n",
      "   11 | 00m46s |    0.79994 |      5.3751 |             24.5851 |       249.6952 | \n",
      "   12 | 00m54s |    0.80121 |      6.1472 |              2.3103 |       249.9393 | \n",
      "   13 | 01m47s |    0.80206 |     28.6203 |             24.9089 |       249.7661 | \n",
      "   14 | 00m49s |    0.79992 |      5.1815 |             23.5018 |       249.7942 | \n",
      "   15 | 01m50s |    0.79867 |     29.7089 |              3.1690 |       249.9904 | \n",
      "RFC: 0.804592\n",
      "Took: 858.7855997085571 seconds to do parameter tuning\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "parameter_search()\n",
    "end   = time.time()\n",
    "\n",
    "print('Took: {} seconds to do parameter tuning'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C | \n",
      "    1 | 00m08s | \u001b[35m   0.78599\u001b[0m | \u001b[32m  89.5155\u001b[0m | \n",
      "    2 | 00m07s |    0.78599 |   78.9667 | \n",
      "    3 | 00m08s |    0.78598 |   13.5476 | \n",
      "    4 | 00m07s |    0.78597 |   66.5578 | \n",
      "    5 | 00m08s |    0.78598 |    4.1060 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C | \n",
      "    6 | 00m12s | \u001b[35m   0.78600\u001b[0m | \u001b[32m   0.0133\u001b[0m | \n",
      "    7 | 00m11s |    0.78597 |   99.9988 | \n",
      "    8 | 00m11s |    0.78599 |    0.0105 | \n",
      "    9 | 00m11s |    0.78596 |   99.9991 | \n",
      "   10 | 00m09s |    0.78599 |    0.0120 | \n",
      "   11 | 00m10s |    0.78598 |   99.9985 | \n",
      "   12 | 00m11s | \u001b[35m   0.78601\u001b[0m | \u001b[32m   0.0102\u001b[0m | \n",
      "   13 | 00m11s |    0.78599 |   99.9971 | \n",
      "   14 | 00m12s |    0.78600 |    0.0124 | \n",
      "   15 | 00m10s |    0.78599 |   99.9994 | \n",
      "Logistic Regression: 0.786013\n",
      "Took: 152.08046293258667 seconds to do parameter tuning\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "parameter_search(rf=False)\n",
    "end   = time.time()\n",
    "\n",
    "print('Took: {} seconds to do parameter tuning'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(X_train, y_train, X_test, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    print('Log Loss on test set: {}'.format(roc_auc_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss on test set: 0.8094791959492946\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=219, \n",
    "                                max_depth=11, \n",
    "                                min_samples_split=19, \n",
    "                                random_state=SEED)\n",
    "    \n",
    "test_model(X_train, y_train, X_test, y_test, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss on test set: 0.7919791187472494\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(C=.01, class_weight='balanced', random_state=SEED)\n",
    "    \n",
    "test_model(X_train, y_train, X_test, y_test, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_training(X, y, Xtest, model, model_name, save=True):\n",
    "    model.fit(X, y)\n",
    "    final_preds = model.predict_proba(Xtest)[:, 1]\n",
    "    \n",
    "    if save:\n",
    "        joblib.dump(model, '../models/%s'%(model_name))\n",
    "        \n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = LogisticRegression(C=.01, class_weight='balanced', random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_preds = full_training(X, y, Xtest, log, 'log_genre_wt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/raw/5f828822-4--4-hotstar_dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub['segment'] = final_preds\n",
    "sub.to_csv('../submissions/hotstar/log_genre_watch_times.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "1331096f8f4b46948215a860ac833af1": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
